{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e451cdee",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Data Scraping with BeautifulSoup\n",
    "    We will use BeautifulSoup by itself, as part of Selenium and as a part of pandas\n",
    "    \n",
    "    We will be scraping data from Pro-Football-Reference (https://www.pro-football-reference.com/).  For this project we will be all team season statistics for the years 2021, 2022, and 2023.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ed6849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Packages for webscraping\n",
    "import random\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import requests\n",
    "import timeit\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de7dec",
   "metadata": {},
   "source": [
    "## What is webscraping and how is it done????\n",
    "To do this we use a package called BeautifulSoup.  First we state the website that we are going to scrap in this case the pro-football-reference San Francisco 49ers page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec99d86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the Website that we are wanting to scrap\n",
    "    ### Statistics are from 2023 SanFransico 49ers\n",
    "url = \"https://www.pro-football-reference.com/teams/sfo/2023.htm\"\n",
    "\n",
    "# This is to get a response object hopefully 200, meaning it was successful\n",
    "page = requests.get(url)\n",
    "\n",
    "# Getting the information from the URL, then running it through our parser\n",
    "soup = BeautifulSoup(page.text, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a689fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8505b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d94ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e65cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a69ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d343f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5343f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4648f6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a97c10b",
   "metadata": {},
   "source": [
    "Lets Start with looking at the address for just one of the NFL teams (Buffalo Bills - https://www.pro-football-reference.com/teams/buf/2023.htm).  We know we will need the season statistics in the Team Stats and Rankings Table, if we look a little lower we can see their conversion rates on 3rd and 4th down as well as in the redzone.  Those are the two tables that we are going to scrap for ever team over 3 seasons.  Lets start by going to the webpage and try and figure out what we need to be looking for to pull the tables from the websites\n",
    "\n",
    "We can see that the website has 3 parts a teams, buf and year or season.  If we select a different team what happens?\n",
    "\n",
    "This shows us that ever team has a specific abbreviation, we will need to create a list of these so we can cycle through the different teams. It may also be helpful to have the teams full name as well.  We can create a library that will assign the teams abbr to its team name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ee03e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of team abbreviations to insert into webaddress\n",
    "team_abbrs = ['atl','rav','buf','car','chi','cin','cle','dal',\n",
    "              'den','det','gnb','htx','clt','jax','kan','sdg','ram',\n",
    "              'rai','mia','min','nwe','nor','nyg','nyj','phi','pit','sea',\n",
    "             'sfo','tam','oti','was','crd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39c26ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of seasons = 3\n"
     ]
    }
   ],
   "source": [
    "# Creates the list of seasons to insert into the webaddress\n",
    "seasons = [str(season) for season in range (2021, 2024)]\n",
    "print(f'number of seasons = {len(seasons)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d4647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92264b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322f672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbe8957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29653e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bf22de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bd97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcf0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5bbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605b59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd988adc",
   "metadata": {},
   "source": [
    "# Data Consolidation and Cleaning\n",
    "    Here we will combine the different dataframes into a model and a test set, so we can begin to train and then test our models.  We will also clean the dataframes, eliminating some variables, create dummy varables and standardize the values. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d473a0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be scraping data from Pro-Football-Reference (https://www.pro-football-reference.com/), "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99819a0d",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "    In this section we will build a function to predict the scores given the two teams that are playing.  We will also build a function that will simulate a playoff bracket by round.  At the end we will have the by round scores for the Wildcard, Divisional, Conference Championship, and Superbowl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ba914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "babbb9c1",
   "metadata": {},
   "source": [
    "# Playoff Bracket Visualization\n",
    "    Here we will create a playoff bracket visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7fa65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbd5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3037ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ca6d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197d1bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c72f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4bb5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0260b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197045a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e597bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
